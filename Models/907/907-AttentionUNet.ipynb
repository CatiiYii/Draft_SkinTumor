{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T12:17:48.056854Z",
     "iopub.status.busy": "2025-10-26T12:17:48.056541Z",
     "iopub.status.idle": "2025-10-26T12:18:53.673782Z",
     "shell.execute_reply": "2025-10-26T12:18:53.673165Z",
     "shell.execute_reply.started": "2025-10-26T12:17:48.056828Z"
    },
    "id": "0ootNdkxxVz6",
    "outputId": "560b159e-4280-45cd-b7bd-7d577f5cfb9f",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/lucasb-eyer/pydensecrf.git\n",
      "  Cloning https://github.com/lucasb-eyer/pydensecrf.git to /tmp/pip-req-build-eht0evab\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/lucasb-eyer/pydensecrf.git /tmp/pip-req-build-eht0evab\n",
      "  Resolved https://github.com/lucasb-eyer/pydensecrf.git to commit 2723c7fa4f2ead16ae1ce3d8afe977724bb8f87f\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: pydensecrf\n",
      "  Building wheel for pydensecrf (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pydensecrf: filename=pydensecrf-1.0-cp311-cp311-linux_x86_64.whl size=3440328 sha256=fd4914a54dc5fa86cb93e3b0f2a04f918b4a803e5a1861f5b425fa486cf3dc1c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-zzaj_4ht/wheels/ce/8e/34/6dcfa200a9e2ae3627d8009b8bd1ca9b24512bec50a93304de\n",
      "Successfully built pydensecrf\n",
      "Installing collected packages: pydensecrf\n",
      "Successfully installed pydensecrf-1.0\n",
      "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-contrib-python) (1.26.4)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-contrib-python) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-contrib-python) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-contrib-python) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-contrib-python) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-contrib-python) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-contrib-python) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.2->opencv-contrib-python) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.2->opencv-contrib-python) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.2->opencv-contrib-python) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21.2->opencv-contrib-python) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21.2->opencv-contrib-python) (2024.2.0)\n",
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons) (25.0)\n",
      "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: typeguard, tensorflow-addons\n",
      "  Attempting uninstall: typeguard\n",
      "    Found existing installation: typeguard 4.4.2\n",
      "    Uninstalling typeguard-4.4.2:\n",
      "      Successfully uninstalled typeguard-4.4.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ydata-profiling 4.16.1 requires typeguard<5,>=3, but you have typeguard 2.13.3 which is incompatible.\n",
      "inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-26 12:18:42.702879: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761481122.871266      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761481122.918374      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/lucasb-eyer/pydensecrf.git\n",
    "!pip install opencv-contrib-python\n",
    "!pip install tensorflow-addons\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Layer, Input, Conv2D, BatchNormalization, Lambda, Concatenate\n",
    "import pydensecrf.densecrf as dcrf\n",
    "from pydensecrf.utils import unary_from_softmax, create_pairwise_bilateral\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, SeparableConv2D, BatchNormalization, MaxPooling2D, UpSampling2D, Conv2DTranspose,\n",
    "    Concatenate, SpatialDropout2D, ReLU, GlobalAveragePooling2D, Add,\n",
    "    GlobalMaxPooling2D, Dense, Reshape, Multiply, Add, Conv2D, Lambda, Activation\n",
    ")\n",
    "from tensorflow.keras.activations import swish\n",
    "from tensorflow.keras.layers import Conv2D, Activation, Add, Multiply, UpSampling2D, Concatenate\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Input, SeparableConv2D, BatchNormalization, MaxPooling2D, Conv2DTranspose, Concatenate, SpatialDropout2D, ReLU, GlobalAveragePooling2D, GlobalMaxPooling2D, Dense, Reshape, Multiply, Add, Conv2D, Lambda\n",
    "from tensorflow.keras.initializers import HeNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-26T12:18:53.675815Z",
     "iopub.status.busy": "2025-10-26T12:18:53.675160Z",
     "iopub.status.idle": "2025-10-26T12:18:53.681364Z",
     "shell.execute_reply": "2025-10-26T12:18:53.680615Z",
     "shell.execute_reply.started": "2025-10-26T12:18:53.675783Z"
    },
    "id": "IfNiEP5ixV0B",
    "outputId": "d1d937c0-ace3-4207-891f-88420d563240",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ xóa thành công /kaggle/working/.virtual_documents\n"
     ]
    }
   ],
   "source": [
    "working_dir = '/kaggle/working'\n",
    "for item in os.listdir(working_dir):\n",
    "    item_path = os.path.join(working_dir, item)\n",
    "    try:\n",
    "        if os.path.isfile(item_path) or os.path.islink(item_path):\n",
    "            os.unlink(item_path)\n",
    "        elif os.path.isdir(item_path):\n",
    "            shutil.rmtree(item_path) \n",
    "            print(f\"❌ xóa thành công {item_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi xóa {item_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T12:18:53.682487Z",
     "iopub.status.busy": "2025-10-26T12:18:53.682232Z",
     "iopub.status.idle": "2025-10-26T12:18:53.717274Z",
     "shell.execute_reply": "2025-10-26T12:18:53.716520Z",
     "shell.execute_reply.started": "2025-10-26T12:18:53.682471Z"
    },
    "id": "joRK3VSRxV0F",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_isic_dataset(image_path, mask_path, binary_path, csv_file, img_size=(256, 256)):\n",
    "    image_files = sorted(glob(os.path.join(image_path, \"ISIC_*.jpg\")))\n",
    "    images = []\n",
    "    masks = []\n",
    "    binary_masks = {}\n",
    "    image_ids = []\n",
    "    labels = []\n",
    "\n",
    "    csv_data = pd.read_csv(csv_file)\n",
    "    mel_label = csv_data['melanoma'].astype(\"int64\")\n",
    "\n",
    "    print(\"Đang đọc và xử lý dữ liệu...\")\n",
    "    for index, img_path in enumerate(tqdm(image_files)):\n",
    "        img_id = os.path.basename(img_path).split('.')[0]\n",
    "        mask_file = os.path.join(mask_path, f\"{img_id}_segmentation.png\")\n",
    "        binary_file = os.path.join(binary_path, f\"{img_id}_features.json\")\n",
    "        if not os.path.exists(mask_file):\n",
    "            print(f\"Không tìm thấy mask cho ảnh mặt nạ {img_id}_segmentation.png\")\n",
    "            continue\n",
    "        if not os.path.exists(binary_file):\n",
    "            print(f\"Không tìm thấy mask nhị phân cho ảnh {img_id}_features.json\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  \n",
    "            mask = cv2.imread(mask_file, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            img = cv2.resize(img, img_size)\n",
    "            mask = cv2.resize(mask, img_size)\n",
    "\n",
    "            img = img / 255.0\n",
    "            mask = mask / 255.0\n",
    "\n",
    "            with open(binary_file, 'r') as f:\n",
    "                binary_masks[img_id] = json.load(f)\n",
    "\n",
    "            label = mel_label[index]\n",
    "\n",
    "            images.append(img)\n",
    "            masks.append(mask)\n",
    "            image_ids.append(img_id)\n",
    "            labels.append(label.astype(\"long\"))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi xử lý ảnh {img_id}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "    images = np.array(images)\n",
    "    masks = np.array(masks)[..., np.newaxis]  \n",
    "    labels = np.array(labels)\n",
    "\n",
    "    print(f\"\\nĐã đọc thành công {len(images)} ảnh\")\n",
    "    print(f\"Shape của images: {images.shape}\")\n",
    "    print(f\"Shape của masks: {masks.shape}\")\n",
    "    print(f\"Shape của labels: {labels.shape}\")\n",
    "\n",
    "    return images, masks, binary_masks, image_ids, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T12:18:53.719451Z",
     "iopub.status.busy": "2025-10-26T12:18:53.718903Z",
     "iopub.status.idle": "2025-10-26T12:20:56.111085Z",
     "shell.execute_reply": "2025-10-26T12:20:56.110308Z",
     "shell.execute_reply.started": "2025-10-26T12:18:53.719433Z"
    },
    "id": "1B5aVPENxV0J",
    "outputId": "5ce27fcc-0289-4036-c82e-7369483e6f22",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang đọc và xử lý dữ liệu...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 635/635 [02:01<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Đã đọc thành công 635 ảnh\n",
      "Shape của images: (635, 256, 256, 3)\n",
      "Shape của masks: (635, 256, 256, 1)\n",
      "Shape của labels: (635,)\n"
     ]
    }
   ],
   "source": [
    "train_images, train_masks, train_binarys, train_image_ids, train_labels = load_isic_dataset(\n",
    "    image_path='/kaggle/input/isic-2017-melanoma/Train_Data',\n",
    "    mask_path='/kaggle/input/isic-2017-melanoma/Train_GroundTruth_1',\n",
    "    binary_path='/kaggle/input/isic-2017-melanoma/Train_GroundTruth_2',\n",
    "    csv_file=\"/kaggle/input/isic-2017-melanoma/Train_GroundTruth_3.csv\",\n",
    "    img_size=(256, 256)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T12:20:56.112208Z",
     "iopub.status.busy": "2025-10-26T12:20:56.111925Z",
     "iopub.status.idle": "2025-10-26T12:21:43.761805Z",
     "shell.execute_reply": "2025-10-26T12:21:43.760932Z",
     "shell.execute_reply.started": "2025-10-26T12:20:56.112184Z"
    },
    "id": "lyk-RBw4xV0L",
    "outputId": "44a6e000-f490-4cd1-fc44-2b0d7eb806ce",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang đọc và xử lý dữ liệu...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:47<00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Đã đọc thành công 272 ảnh\n",
      "Shape của images: (272, 256, 256, 3)\n",
      "Shape của masks: (272, 256, 256, 1)\n",
      "Shape của labels: (272,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_images, test_masks, test_binarys, test_image_ids, test_labels = load_isic_dataset(\n",
    "    image_path='/kaggle/input/isic-2017-melanoma/Test_Data',\n",
    "    mask_path='/kaggle/input/isic-2017-melanoma/Test_GroundTruth_1',\n",
    "    binary_path='/kaggle/input/isic-2017-melanoma/Test_GroundTruth_2',\n",
    "    csv_file='/kaggle/input/isic-2017-melanoma/Test_GroundTruth_3.csv',\n",
    "    img_size=(256, 256)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T12:21:43.762977Z",
     "iopub.status.busy": "2025-10-26T12:21:43.762676Z",
     "iopub.status.idle": "2025-10-26T12:21:43.767348Z",
     "shell.execute_reply": "2025-10-26T12:21:43.766540Z",
     "shell.execute_reply.started": "2025-10-26T12:21:43.762957Z"
    },
    "id": "wLBKwiGMxV0N",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def iou_metric(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
    "    iou = (intersection + 1e-7) / (union + 1e-7)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T12:21:43.768362Z",
     "iopub.status.busy": "2025-10-26T12:21:43.768124Z",
     "iopub.status.idle": "2025-10-26T12:21:43.782171Z",
     "shell.execute_reply": "2025-10-26T12:21:43.781472Z",
     "shell.execute_reply.started": "2025-10-26T12:21:43.768341Z"
    },
    "id": "Hb2eQ-stxV0Q",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metric(y_true, y_pred, metric='dice_coefficient', smooth=1e-6, is_numpy=False):\n",
    "    y_true_f = y_true.flatten() if is_numpy else K.flatten(y_true)\n",
    "    y_pred_f = y_pred.flatten() if is_numpy else K.flatten(y_pred)\n",
    "    intersection = np.sum(y_true_f * y_pred_f) if is_numpy else K.sum(y_true_f * y_pred_f)\n",
    "\n",
    "    if 'dice' in metric:\n",
    "        sum_fn = np.sum if is_numpy else K.sum\n",
    "        score = (2. * intersection + smooth) / (sum_fn(y_true_f) + sum_fn(y_pred_f) + smooth)\n",
    "    elif 'jaccard' in metric:\n",
    "        sum_fn = np.sum if is_numpy else K.sum\n",
    "        union = sum_fn(y_true_f) + sum_fn(y_pred_f) - intersection\n",
    "        score = (intersection + smooth) / (union + smooth)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported metric: {metric}\")\n",
    "\n",
    "    return score if 'coefficient' in metric else 1 - score\n",
    "\n",
    "def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
    "    return compute_metric(y_true, y_pred, 'dice_coefficient', smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred, smooth=1e-6):\n",
    "    return compute_metric(y_true, y_pred, 'dice_loss', smooth)\n",
    "\n",
    "def jaccard_coefficient(y_true, y_pred, smooth=1e-6):\n",
    "    return compute_metric(y_true, y_pred, 'jaccard_coefficient', smooth)\n",
    "\n",
    "def jaccard_loss(y_true, y_pred, smooth=1e-6):\n",
    "    return compute_metric(y_true, y_pred, 'jaccard_loss', smooth)\n",
    "\n",
    "def np_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true.flatten() == y_pred.flatten())\n",
    "\n",
    "def np_dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
    "    return compute_metric(y_true, y_pred, 'dice_coefficient', smooth, is_numpy=True)\n",
    "\n",
    "def np_jaccard_coefficient(y_true, y_pred, smooth=1e-6):\n",
    "    return compute_metric(y_true, y_pred, 'jaccard_coefficient', smooth, is_numpy=True)\n",
    "\n",
    "def np_dice_loss(y_true, y_pred, smooth=1e-6):\n",
    "    return compute_metric(y_true, y_pred, 'dice_loss', smooth, is_numpy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T12:21:43.783116Z",
     "iopub.status.busy": "2025-10-26T12:21:43.782891Z",
     "iopub.status.idle": "2025-10-26T12:21:46.167197Z",
     "shell.execute_reply": "2025-10-26T12:21:46.166428Z",
     "shell.execute_reply.started": "2025-10-26T12:21:43.783100Z"
    },
    "id": "oqxLgfn8xV0T",
    "outputId": "89c4cf15-fdd2-4898-8101-08dd3e3694f1",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1761481304.756838      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Attention-UNET\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Attention-UNET\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_3… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_4… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling2d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_6… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_7… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ up_sampling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ up_sampling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│                           │                        │                │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │ activation_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│                           │                        │                │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ up_sampling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                           │                        │                │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,769,728</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ activation_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_9     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_10             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_9… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ up_sampling2d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ up_sampling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│                           │                        │                │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_11             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ activation_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ multiply_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│                           │                        │                │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ up_sampling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ multiply_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">442,496</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_10    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_12             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_11    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_13             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ up_sampling2d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ up_sampling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│                           │                        │                │ conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_14             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ activation_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ multiply_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│                           │                        │                │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ up_sampling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ multiply_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">110,656</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_12    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_15             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_13    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_16             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ activation_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m640\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │         \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_2… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m147,584\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_3… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m295,168\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_4… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m590,080\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_5… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ max_pooling2d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m1,180,160\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_6… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │      \u001b[38;5;34m2,359,808\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m2,048\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_7 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_7… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ up_sampling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mUpSampling2D\u001b[0m)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m131,328\u001b[0m │ up_sampling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m65,792\u001b[0m │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│                           │                        │                │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_8 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │            \u001b[38;5;34m257\u001b[0m │ activation_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ multiply (\u001b[38;5;33mMultiply\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│                           │                        │                │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m768\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ up_sampling2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                           │                        │                │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m1,769,728\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_9 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_8… │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m590,080\u001b[0m │ activation_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_9     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_10             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_9… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ up_sampling2d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mUpSampling2D\u001b[0m)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │         \u001b[38;5;34m32,896\u001b[0m │ up_sampling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │         \u001b[38;5;34m16,512\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│                           │                        │                │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_11             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │            \u001b[38;5;34m129\u001b[0m │ activation_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ multiply_1 (\u001b[38;5;33mMultiply\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│                           │                        │                │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m384\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ up_sampling2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ multiply_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m442,496\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_10    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_12             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m147,584\u001b[0m │ activation_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_11    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │            \u001b[38;5;34m512\u001b[0m │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_13             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ up_sampling2d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ activation_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mUpSampling2D\u001b[0m)            │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m8,256\u001b[0m │ up_sampling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m4,160\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│                           │                        │                │ conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_14             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m65\u001b[0m │ activation_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ multiply_2 (\u001b[38;5;33mMultiply\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv2d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│                           │                        │                │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ concatenate_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m192\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ up_sampling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ multiply_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m110,656\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_12    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_15             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ activation_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ batch_normalization_13    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ activation_16             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m65\u001b[0m │ activation_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,052,420</span> (30.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,052,420\u001b[0m (30.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,046,788</span> (30.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,046,788\u001b[0m (30.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,632</span> (22.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m5,632\u001b[0m (22.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def conv_block(x, num_filters):\n",
    "    x = L.Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Activation(\"relu\")(x)\n",
    "\n",
    "    x = L.Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def encoder_block(x, num_filters):\n",
    "    x = conv_block(x, num_filters)\n",
    "    p = L.MaxPool2D((2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "def attention_gate(g, s, num_filters):\n",
    "    Wg = L.Conv2D(num_filters, 1, padding=\"same\")(g)\n",
    "\n",
    "    Ws = L.Conv2D(num_filters, 1, padding=\"same\")(s)\n",
    "\n",
    "    out = L.Activation(\"relu\")(Wg + Ws)\n",
    "\n",
    "    psi = L.Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(out)\n",
    "\n",
    "    return psi * s\n",
    "\n",
    "def decoder_block(x, s, num_filters):\n",
    "    x = L.UpSampling2D(interpolation=\"bilinear\")(x)\n",
    "    s = attention_gate(x, s, num_filters)\n",
    "    x = L.Concatenate()([x, s])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def attention_unet(input_shape):\n",
    "    inputs = L.Input(input_shape)\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "\n",
    "    b1 = conv_block(p3, 512)\n",
    "\n",
    "    d1 = decoder_block(b1, s3, 256)\n",
    "    d2 = decoder_block(d1, s2, 128)\n",
    "    d3 = decoder_block(d2, s1, 64)\n",
    "\n",
    "    outputs = L.Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d3)\n",
    "\n",
    "    model = Model(inputs, outputs, name=\"Attention-UNET\")\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_shape = (256, 256, 1)\n",
    "    model = attention_unet(input_shape)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T12:21:46.168183Z",
     "iopub.status.busy": "2025-10-26T12:21:46.168001Z",
     "iopub.status.idle": "2025-10-26T12:21:46.174986Z",
     "shell.execute_reply": "2025-10-26T12:21:46.174349Z",
     "shell.execute_reply.started": "2025-10-26T12:21:46.168169Z"
    },
    "id": "rAJRCVhRxV0Y",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EarlyStoppingByAccuracyChange(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, monitor='accuracy', threshold=0.00001, patience=3, verbose=0):\n",
    "        super(EarlyStoppingByAccuracyChange, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.threshold = threshold\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.wait = 0\n",
    "        self.best_accuracy = -float('inf')\n",
    "        self.consecutive_stops = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        current_accuracy = logs.get(self.monitor)\n",
    "        if current_accuracy is None:\n",
    "            tf.get_logger().warning(\n",
    "                'Early stopping requires %s available!', self.monitor\n",
    "            )\n",
    "            return\n",
    "\n",
    "        if current_accuracy > self.best_accuracy:\n",
    "            self.best_accuracy = current_accuracy\n",
    "            self.wait = 0\n",
    "            self.consecutive_stops = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            accuracy_change = current_accuracy - self.best_accuracy\n",
    "            if abs(accuracy_change) < self.threshold:\n",
    "                self.consecutive_stops += 1\n",
    "                if self.consecutive_stops >= self.patience:\n",
    "                    if self.verbose > 0:\n",
    "                        print(f\"Epoch {epoch+1}: Early stopping triggered due to minimal accuracy change for {self.patience} epochs.\")\n",
    "                    self.model.stop_training = True\n",
    "            else:\n",
    "                self.consecutive_stops = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T12:21:46.177485Z",
     "iopub.status.busy": "2025-10-26T12:21:46.177294Z",
     "iopub.status.idle": "2025-10-26T12:21:49.123207Z",
     "shell.execute_reply": "2025-10-26T12:21:49.122314Z",
     "shell.execute_reply.started": "2025-10-26T12:21:46.177471Z"
    },
    "id": "9sT4HUCaxV0c",
    "outputId": "ed45a279-ec3f-4728-a8b1-c1f9e840110d",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-contrib-python) (1.26.4)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-contrib-python) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-contrib-python) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-contrib-python) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-contrib-python) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-contrib-python) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-contrib-python) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.2->opencv-contrib-python) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.2->opencv-contrib-python) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.2->opencv-contrib-python) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21.2->opencv-contrib-python) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21.2->opencv-contrib-python) (2024.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-contrib-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T12:21:49.124595Z",
     "iopub.status.busy": "2025-10-26T12:21:49.124266Z",
     "iopub.status.idle": "2025-10-26T12:21:49.921954Z",
     "shell.execute_reply": "2025-10-26T12:21:49.921288Z",
     "shell.execute_reply.started": "2025-10-26T12:21:49.124558Z"
    },
    "id": "mWbMPV2dxV0d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def convert_to_gray_clahe(images):\n",
    "    grays = []\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))   \n",
    "\n",
    "    for img in images:\n",
    "        if img.dtype != np.uint8:\n",
    "            img = (img * 255).astype(np.uint8)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) \n",
    "\n",
    "        img_clahe = clahe.apply(gray)  \n",
    "        grays.append(img_clahe)\n",
    "\n",
    "    return np.array(grays)\n",
    "\n",
    "train_images_gray_clahe = convert_to_gray_clahe(train_images)\n",
    "test_images_gray_clahe = convert_to_gray_clahe(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T12:21:49.923029Z",
     "iopub.status.busy": "2025-10-26T12:21:49.922804Z",
     "iopub.status.idle": "2025-10-26T13:17:53.353467Z",
     "shell.execute_reply": "2025-10-26T13:17:53.352688Z",
     "shell.execute_reply.started": "2025-10-26T12:21:49.923013Z"
    },
    "id": "qrekiytCxV0f",
    "outputId": "f858feca-3119-42d7-a768-796990464fb7",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1761481326.384856     193 service.cc:148] XLA service 0x7b837000e920 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1761481326.385474     193 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1761481327.893252     193 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-10-26 12:22:14.434088: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng12{k11=2} for conv (f32[32,128,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,128,128]{3,2,1,0}, f32[128,128,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2025-10-26 12:22:14.469960: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.036134236s\n",
      "Trying algorithm eng12{k11=2} for conv (f32[32,128,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,128,128,128]{3,2,1,0}, f32[128,128,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2025-10-26 12:22:36.794689: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng2{k2=3,k3=0} for conv (f32[32,192,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,256,256]{3,2,1,0}, f32[64,192,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2025-10-26 12:22:37.213375: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.418777729s\n",
      "Trying algorithm eng2{k2=3,k3=0} for conv (f32[32,192,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,256,256]{3,2,1,0}, f32[64,192,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "I0000 00:00:1761481395.199838     193 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 2s/step - accuracy: 0.7493 - jaccard_coefficient: 0.3464 - loss: 0.4961"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1761481431.641661     192 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1761481431.881923     192 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1761481433.089384     192 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1761481433.354505     192 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1761481438.781528     192 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1761481439.022626     192 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-10-26 12:24:10.558480: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng2{k2=3,k3=0} for conv (f32[27,192,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[27,64,256,256]{3,2,1,0}, f32[64,192,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2025-10-26 12:24:10.770346: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.21197911s\n",
      "Trying algorithm eng2{k2=3,k3=0} for conv (f32[27,192,256,256]{3,2,1,0}, u8[0]{0}) custom-call(f32[27,64,256,256]{3,2,1,0}, f32[64,192,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "E0000 00:00:1761481455.991480     192 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1761481456.233639     192 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.7512 - jaccard_coefficient: 0.3497 - loss: 0.4925\n",
      "Epoch 1: loss improved from inf to 0.42407, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 5s/step - accuracy: 0.7528 - jaccard_coefficient: 0.3526 - loss: 0.4893 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8131 - jaccard_coefficient: 0.4853 - loss: 0.3484\n",
      "Epoch 2: loss improved from 0.42407 to 0.34739, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.8135 - jaccard_coefficient: 0.4854 - loss: 0.3483 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8542 - jaccard_coefficient: 0.5284 - loss: 0.3097\n",
      "Epoch 3: loss improved from 0.34739 to 0.31082, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.8541 - jaccard_coefficient: 0.5284 - loss: 0.3098 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8596 - jaccard_coefficient: 0.5465 - loss: 0.2944\n",
      "Epoch 4: loss improved from 0.31082 to 0.30171, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.8593 - jaccard_coefficient: 0.5461 - loss: 0.2947 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8535 - jaccard_coefficient: 0.5352 - loss: 0.3049\n",
      "Epoch 5: loss improved from 0.30171 to 0.28261, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.8540 - jaccard_coefficient: 0.5365 - loss: 0.3038 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8710 - jaccard_coefficient: 0.5713 - loss: 0.2736\n",
      "Epoch 6: loss improved from 0.28261 to 0.27586, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.8708 - jaccard_coefficient: 0.5712 - loss: 0.2737 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8714 - jaccard_coefficient: 0.5619 - loss: 0.2828\n",
      "Epoch 7: loss did not improve from 0.27586\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.8710 - jaccard_coefficient: 0.5618 - loss: 0.2829 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8701 - jaccard_coefficient: 0.5759 - loss: 0.2701\n",
      "Epoch 8: loss improved from 0.27586 to 0.27381, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.8699 - jaccard_coefficient: 0.5757 - loss: 0.2703 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8670 - jaccard_coefficient: 0.5709 - loss: 0.2742\n",
      "Epoch 9: loss improved from 0.27381 to 0.27250, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.8672 - jaccard_coefficient: 0.5710 - loss: 0.2741 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8649 - jaccard_coefficient: 0.5579 - loss: 0.2854\n",
      "Epoch 10: loss did not improve from 0.27250\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.8649 - jaccard_coefficient: 0.5583 - loss: 0.2851 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8731 - jaccard_coefficient: 0.5939 - loss: 0.2562\n",
      "Epoch 11: loss improved from 0.27250 to 0.26186, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.8731 - jaccard_coefficient: 0.5936 - loss: 0.2565 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8825 - jaccard_coefficient: 0.6140 - loss: 0.2401\n",
      "Epoch 12: loss improved from 0.26186 to 0.25211, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.8823 - jaccard_coefficient: 0.6133 - loss: 0.2406 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8840 - jaccard_coefficient: 0.6064 - loss: 0.2462\n",
      "Epoch 13: loss improved from 0.25211 to 0.23997, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.8841 - jaccard_coefficient: 0.6069 - loss: 0.2459 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8834 - jaccard_coefficient: 0.6158 - loss: 0.2399\n",
      "Epoch 14: loss did not improve from 0.23997\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.8834 - jaccard_coefficient: 0.6154 - loss: 0.2403 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8777 - jaccard_coefficient: 0.5911 - loss: 0.2580\n",
      "Epoch 15: loss did not improve from 0.23997\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.8778 - jaccard_coefficient: 0.5913 - loss: 0.2579 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8859 - jaccard_coefficient: 0.6195 - loss: 0.2357\n",
      "Epoch 16: loss did not improve from 0.23997\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.8859 - jaccard_coefficient: 0.6192 - loss: 0.2360 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8907 - jaccard_coefficient: 0.6259 - loss: 0.2304\n",
      "Epoch 17: loss improved from 0.23997 to 0.23242, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.8906 - jaccard_coefficient: 0.6257 - loss: 0.2305 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8946 - jaccard_coefficient: 0.6350 - loss: 0.2243\n",
      "Epoch 18: loss improved from 0.23242 to 0.22184, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.8946 - jaccard_coefficient: 0.6352 - loss: 0.2242 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8966 - jaccard_coefficient: 0.6486 - loss: 0.2137\n",
      "Epoch 19: loss did not improve from 0.22184\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.8965 - jaccard_coefficient: 0.6481 - loss: 0.2141 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9012 - jaccard_coefficient: 0.6425 - loss: 0.2196\n",
      "Epoch 20: loss did not improve from 0.22184\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9007 - jaccard_coefficient: 0.6418 - loss: 0.2201 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8843 - jaccard_coefficient: 0.6133 - loss: 0.2429\n",
      "Epoch 21: loss did not improve from 0.22184\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.8845 - jaccard_coefficient: 0.6136 - loss: 0.2426 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8802 - jaccard_coefficient: 0.6081 - loss: 0.2447\n",
      "Epoch 22: loss did not improve from 0.22184\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.8803 - jaccard_coefficient: 0.6083 - loss: 0.2446 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8994 - jaccard_coefficient: 0.6431 - loss: 0.2184\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 23: loss did not improve from 0.22184\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.8991 - jaccard_coefficient: 0.6427 - loss: 0.2187 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8973 - jaccard_coefficient: 0.6396 - loss: 0.2204\n",
      "Epoch 24: loss improved from 0.22184 to 0.21487, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.8973 - jaccard_coefficient: 0.6400 - loss: 0.2201 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9003 - jaccard_coefficient: 0.6618 - loss: 0.2048\n",
      "Epoch 25: loss improved from 0.21487 to 0.21201, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9002 - jaccard_coefficient: 0.6613 - loss: 0.2051 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9027 - jaccard_coefficient: 0.6432 - loss: 0.2184\n",
      "Epoch 26: loss improved from 0.21201 to 0.20945, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9027 - jaccard_coefficient: 0.6437 - loss: 0.2179 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9024 - jaccard_coefficient: 0.6771 - loss: 0.1931\n",
      "Epoch 27: loss improved from 0.20945 to 0.19581, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9026 - jaccard_coefficient: 0.6769 - loss: 0.1933 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9110 - jaccard_coefficient: 0.6674 - loss: 0.2001\n",
      "Epoch 28: loss did not improve from 0.19581\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9108 - jaccard_coefficient: 0.6673 - loss: 0.2002 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9120 - jaccard_coefficient: 0.6904 - loss: 0.1836\n",
      "Epoch 29: loss improved from 0.19581 to 0.19008, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9120 - jaccard_coefficient: 0.6900 - loss: 0.1839 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9045 - jaccard_coefficient: 0.6710 - loss: 0.1973\n",
      "Epoch 30: loss did not improve from 0.19008\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9047 - jaccard_coefficient: 0.6712 - loss: 0.1971 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9146 - jaccard_coefficient: 0.6956 - loss: 0.1802\n",
      "Epoch 31: loss improved from 0.19008 to 0.18120, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9145 - jaccard_coefficient: 0.6956 - loss: 0.1802 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9209 - jaccard_coefficient: 0.7061 - loss: 0.1728\n",
      "Epoch 32: loss did not improve from 0.18120\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9205 - jaccard_coefficient: 0.7054 - loss: 0.1733 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9102 - jaccard_coefficient: 0.6833 - loss: 0.1890\n",
      "Epoch 33: loss did not improve from 0.18120\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9103 - jaccard_coefficient: 0.6834 - loss: 0.1890 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9059 - jaccard_coefficient: 0.6819 - loss: 0.1900\n",
      "Epoch 34: loss did not improve from 0.18120\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9061 - jaccard_coefficient: 0.6820 - loss: 0.1899 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9123 - jaccard_coefficient: 0.6872 - loss: 0.1860\n",
      "Epoch 35: loss did not improve from 0.18120\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9122 - jaccard_coefficient: 0.6868 - loss: 0.1862 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9188 - jaccard_coefficient: 0.6982 - loss: 0.1784\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 36: loss did not improve from 0.18120\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9184 - jaccard_coefficient: 0.6975 - loss: 0.1789 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9200 - jaccard_coefficient: 0.7033 - loss: 0.1747\n",
      "Epoch 37: loss improved from 0.18120 to 0.16742, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9200 - jaccard_coefficient: 0.7038 - loss: 0.1743 - learning_rate: 2.5000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9219 - jaccard_coefficient: 0.7119 - loss: 0.1690\n",
      "Epoch 38: loss did not improve from 0.16742\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9218 - jaccard_coefficient: 0.7118 - loss: 0.1691 - learning_rate: 2.5000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9269 - jaccard_coefficient: 0.7232 - loss: 0.1609\n",
      "Epoch 39: loss improved from 0.16742 to 0.15900, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9268 - jaccard_coefficient: 0.7233 - loss: 0.1608 - learning_rate: 2.5000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9213 - jaccard_coefficient: 0.7205 - loss: 0.1631\n",
      "Epoch 40: loss did not improve from 0.15900\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9214 - jaccard_coefficient: 0.7206 - loss: 0.1630 - learning_rate: 2.5000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9267 - jaccard_coefficient: 0.7232 - loss: 0.1611\n",
      "Epoch 41: loss did not improve from 0.15900\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9266 - jaccard_coefficient: 0.7233 - loss: 0.1611 - learning_rate: 2.5000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9236 - jaccard_coefficient: 0.7247 - loss: 0.1604\n",
      "Epoch 42: loss improved from 0.15900 to 0.15524, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9238 - jaccard_coefficient: 0.7251 - loss: 0.1601 - learning_rate: 2.5000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9257 - jaccard_coefficient: 0.7201 - loss: 0.1632\n",
      "Epoch 43: loss did not improve from 0.15524\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9256 - jaccard_coefficient: 0.7201 - loss: 0.1632 - learning_rate: 2.5000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9287 - jaccard_coefficient: 0.7418 - loss: 0.1489\n",
      "Epoch 44: loss did not improve from 0.15524\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9286 - jaccard_coefficient: 0.7411 - loss: 0.1494 - learning_rate: 2.5000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9317 - jaccard_coefficient: 0.7459 - loss: 0.1460\n",
      "Epoch 45: loss improved from 0.15524 to 0.15452, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9315 - jaccard_coefficient: 0.7453 - loss: 0.1464 - learning_rate: 2.5000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9269 - jaccard_coefficient: 0.7354 - loss: 0.1528\n",
      "Epoch 46: loss improved from 0.15452 to 0.15251, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9270 - jaccard_coefficient: 0.7354 - loss: 0.1527 - learning_rate: 2.5000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9288 - jaccard_coefficient: 0.7480 - loss: 0.1447\n",
      "Epoch 47: loss did not improve from 0.15251\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9287 - jaccard_coefficient: 0.7474 - loss: 0.1451 - learning_rate: 2.5000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9323 - jaccard_coefficient: 0.7451 - loss: 0.1466\n",
      "Epoch 48: loss did not improve from 0.15251\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9321 - jaccard_coefficient: 0.7446 - loss: 0.1469 - learning_rate: 2.5000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9311 - jaccard_coefficient: 0.7388 - loss: 0.1516\n",
      "Epoch 49: loss improved from 0.15251 to 0.14747, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9311 - jaccard_coefficient: 0.7391 - loss: 0.1514 - learning_rate: 2.5000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9312 - jaccard_coefficient: 0.7392 - loss: 0.1507\n",
      "Epoch 50: loss did not improve from 0.14747\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9312 - jaccard_coefficient: 0.7393 - loss: 0.1506 - learning_rate: 2.5000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9330 - jaccard_coefficient: 0.7558 - loss: 0.1396\n",
      "Epoch 51: loss improved from 0.14747 to 0.13838, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9331 - jaccard_coefficient: 0.7558 - loss: 0.1395 - learning_rate: 2.5000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9300 - jaccard_coefficient: 0.7507 - loss: 0.1432\n",
      "Epoch 52: loss did not improve from 0.13838\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9301 - jaccard_coefficient: 0.7506 - loss: 0.1433 - learning_rate: 2.5000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9357 - jaccard_coefficient: 0.7634 - loss: 0.1345\n",
      "Epoch 53: loss did not improve from 0.13838\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9356 - jaccard_coefficient: 0.7628 - loss: 0.1349 - learning_rate: 2.5000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9314 - jaccard_coefficient: 0.7472 - loss: 0.1453\n",
      "Epoch 54: loss did not improve from 0.13838\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9315 - jaccard_coefficient: 0.7475 - loss: 0.1451 - learning_rate: 2.5000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9388 - jaccard_coefficient: 0.7681 - loss: 0.1314\n",
      "Epoch 55: loss improved from 0.13838 to 0.13087, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9388 - jaccard_coefficient: 0.7682 - loss: 0.1314 - learning_rate: 2.5000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9344 - jaccard_coefficient: 0.7677 - loss: 0.1316\n",
      "Epoch 56: loss improved from 0.13087 to 0.12775, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9346 - jaccard_coefficient: 0.7680 - loss: 0.1315 - learning_rate: 2.5000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9405 - jaccard_coefficient: 0.7761 - loss: 0.1269\n",
      "Epoch 57: loss did not improve from 0.12775\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9404 - jaccard_coefficient: 0.7757 - loss: 0.1271 - learning_rate: 2.5000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9357 - jaccard_coefficient: 0.7555 - loss: 0.1400\n",
      "Epoch 58: loss did not improve from 0.12775\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9358 - jaccard_coefficient: 0.7560 - loss: 0.1397 - learning_rate: 2.5000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9402 - jaccard_coefficient: 0.7702 - loss: 0.1305\n",
      "Epoch 59: loss improved from 0.12775 to 0.12518, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9403 - jaccard_coefficient: 0.7705 - loss: 0.1303 - learning_rate: 2.5000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9379 - jaccard_coefficient: 0.7787 - loss: 0.1248\n",
      "Epoch 60: loss did not improve from 0.12518\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9380 - jaccard_coefficient: 0.7785 - loss: 0.1249 - learning_rate: 2.5000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9439 - jaccard_coefficient: 0.7888 - loss: 0.1183\n",
      "Epoch 61: loss improved from 0.12518 to 0.12218, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9438 - jaccard_coefficient: 0.7885 - loss: 0.1185 - learning_rate: 2.5000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9427 - jaccard_coefficient: 0.7897 - loss: 0.1176\n",
      "Epoch 62: loss improved from 0.12218 to 0.11977, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9427 - jaccard_coefficient: 0.7896 - loss: 0.1177 - learning_rate: 2.5000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9456 - jaccard_coefficient: 0.7905 - loss: 0.1172\n",
      "Epoch 63: loss improved from 0.11977 to 0.11712, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9456 - jaccard_coefficient: 0.7906 - loss: 0.1172 - learning_rate: 2.5000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9497 - jaccard_coefficient: 0.8025 - loss: 0.1100\n",
      "Epoch 64: loss improved from 0.11712 to 0.11598, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9495 - jaccard_coefficient: 0.8020 - loss: 0.1103 - learning_rate: 2.5000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9452 - jaccard_coefficient: 0.7921 - loss: 0.1171\n",
      "Epoch 65: loss did not improve from 0.11598\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9450 - jaccard_coefficient: 0.7916 - loss: 0.1174 - learning_rate: 2.5000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9430 - jaccard_coefficient: 0.7845 - loss: 0.1217\n",
      "Epoch 66: loss improved from 0.11598 to 0.11425, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9432 - jaccard_coefficient: 0.7851 - loss: 0.1213 - learning_rate: 2.5000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9490 - jaccard_coefficient: 0.8051 - loss: 0.1084\n",
      "Epoch 67: loss improved from 0.11425 to 0.10906, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9490 - jaccard_coefficient: 0.8051 - loss: 0.1084 - learning_rate: 2.5000e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9525 - jaccard_coefficient: 0.8178 - loss: 0.1010\n",
      "Epoch 68: loss improved from 0.10906 to 0.10506, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9524 - jaccard_coefficient: 0.8174 - loss: 0.1012 - learning_rate: 2.5000e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9456 - jaccard_coefficient: 0.8019 - loss: 0.1101\n",
      "Epoch 69: loss did not improve from 0.10506\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9458 - jaccard_coefficient: 0.8021 - loss: 0.1100 - learning_rate: 2.5000e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9474 - jaccard_coefficient: 0.8035 - loss: 0.1094\n",
      "Epoch 70: loss did not improve from 0.10506\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9474 - jaccard_coefficient: 0.8035 - loss: 0.1094 - learning_rate: 2.5000e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9522 - jaccard_coefficient: 0.8190 - loss: 0.0998\n",
      "Epoch 71: loss improved from 0.10506 to 0.10362, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9522 - jaccard_coefficient: 0.8187 - loss: 0.1000 - learning_rate: 2.5000e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9504 - jaccard_coefficient: 0.8015 - loss: 0.1104\n",
      "Epoch 72: loss did not improve from 0.10362\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9503 - jaccard_coefficient: 0.8018 - loss: 0.1102 - learning_rate: 2.5000e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9528 - jaccard_coefficient: 0.8165 - loss: 0.1015\n",
      "Epoch 73: loss did not improve from 0.10362\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9527 - jaccard_coefficient: 0.8163 - loss: 0.1016 - learning_rate: 2.5000e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9525 - jaccard_coefficient: 0.8195 - loss: 0.0995\n",
      "Epoch 74: loss improved from 0.10362 to 0.10016, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9525 - jaccard_coefficient: 0.8194 - loss: 0.0996 - learning_rate: 2.5000e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9542 - jaccard_coefficient: 0.8259 - loss: 0.0959\n",
      "Epoch 75: loss did not improve from 0.10016\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9540 - jaccard_coefficient: 0.8252 - loss: 0.0963 - learning_rate: 2.5000e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9532 - jaccard_coefficient: 0.8236 - loss: 0.0970\n",
      "Epoch 76: loss did not improve from 0.10016\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9531 - jaccard_coefficient: 0.8231 - loss: 0.0973 - learning_rate: 2.5000e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9493 - jaccard_coefficient: 0.8115 - loss: 0.1045\n",
      "Epoch 77: loss did not improve from 0.10016\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9494 - jaccard_coefficient: 0.8115 - loss: 0.1045 - learning_rate: 2.5000e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9569 - jaccard_coefficient: 0.8304 - loss: 0.0931\n",
      "Epoch 78: loss improved from 0.10016 to 0.09403, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9568 - jaccard_coefficient: 0.8303 - loss: 0.0932 - learning_rate: 2.5000e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9589 - jaccard_coefficient: 0.8396 - loss: 0.0876\n",
      "Epoch 79: loss improved from 0.09403 to 0.08565, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9590 - jaccard_coefficient: 0.8397 - loss: 0.0875 - learning_rate: 2.5000e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9599 - jaccard_coefficient: 0.8430 - loss: 0.0854\n",
      "Epoch 80: loss improved from 0.08565 to 0.08280, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9599 - jaccard_coefficient: 0.8432 - loss: 0.0852 - learning_rate: 2.5000e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9612 - jaccard_coefficient: 0.8504 - loss: 0.0812\n",
      "Epoch 81: loss did not improve from 0.08280\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9611 - jaccard_coefficient: 0.8500 - loss: 0.0814 - learning_rate: 2.5000e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9629 - jaccard_coefficient: 0.8516 - loss: 0.0803\n",
      "Epoch 82: loss did not improve from 0.08280\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9627 - jaccard_coefficient: 0.8510 - loss: 0.0806 - learning_rate: 2.5000e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9616 - jaccard_coefficient: 0.8490 - loss: 0.0819\n",
      "Epoch 83: loss did not improve from 0.08280\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9615 - jaccard_coefficient: 0.8487 - loss: 0.0821 - learning_rate: 2.5000e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9625 - jaccard_coefficient: 0.8487 - loss: 0.0819\n",
      "Epoch 84: loss improved from 0.08280 to 0.08027, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9624 - jaccard_coefficient: 0.8488 - loss: 0.0819 - learning_rate: 2.5000e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9647 - jaccard_coefficient: 0.8565 - loss: 0.0775\n",
      "Epoch 85: loss improved from 0.08027 to 0.07471, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9647 - jaccard_coefficient: 0.8567 - loss: 0.0774 - learning_rate: 2.5000e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9635 - jaccard_coefficient: 0.8544 - loss: 0.0788\n",
      "Epoch 86: loss did not improve from 0.07471\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9635 - jaccard_coefficient: 0.8544 - loss: 0.0788 - learning_rate: 2.5000e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9608 - jaccard_coefficient: 0.8542 - loss: 0.0789\n",
      "Epoch 87: loss did not improve from 0.07471\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9608 - jaccard_coefficient: 0.8540 - loss: 0.0790 - learning_rate: 2.5000e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9624 - jaccard_coefficient: 0.8451 - loss: 0.0845\n",
      "Epoch 88: loss did not improve from 0.07471\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9625 - jaccard_coefficient: 0.8458 - loss: 0.0841 - learning_rate: 2.5000e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9699 - jaccard_coefficient: 0.8793 - loss: 0.0644\n",
      "Epoch 89: loss improved from 0.07471 to 0.06477, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9699 - jaccard_coefficient: 0.8793 - loss: 0.0644 - learning_rate: 2.5000e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9700 - jaccard_coefficient: 0.8838 - loss: 0.0618\n",
      "Epoch 90: loss improved from 0.06477 to 0.06432, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9700 - jaccard_coefficient: 0.8836 - loss: 0.0619 - learning_rate: 2.5000e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9673 - jaccard_coefficient: 0.8747 - loss: 0.0670\n",
      "Epoch 91: loss did not improve from 0.06432\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9672 - jaccard_coefficient: 0.8744 - loss: 0.0672 - learning_rate: 2.5000e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9714 - jaccard_coefficient: 0.8874 - loss: 0.0598\n",
      "Epoch 92: loss did not improve from 0.06432\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9712 - jaccard_coefficient: 0.8868 - loss: 0.0601 - learning_rate: 2.5000e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9644 - jaccard_coefficient: 0.8613 - loss: 0.0747\n",
      "Epoch 93: loss did not improve from 0.06432\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9645 - jaccard_coefficient: 0.8615 - loss: 0.0746 - learning_rate: 2.5000e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9695 - jaccard_coefficient: 0.8795 - loss: 0.0642\n",
      "Epoch 94: loss did not improve from 0.06432\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9695 - jaccard_coefficient: 0.8793 - loss: 0.0643 - learning_rate: 2.5000e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9687 - jaccard_coefficient: 0.8776 - loss: 0.0653\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 95: loss did not improve from 0.06432\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9687 - jaccard_coefficient: 0.8776 - loss: 0.0652 - learning_rate: 2.5000e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9750 - jaccard_coefficient: 0.8959 - loss: 0.0550\n",
      "Epoch 96: loss improved from 0.06432 to 0.05542, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9749 - jaccard_coefficient: 0.8958 - loss: 0.0550 - learning_rate: 1.2500e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9766 - jaccard_coefficient: 0.9070 - loss: 0.0488\n",
      "Epoch 97: loss improved from 0.05542 to 0.05256, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9765 - jaccard_coefficient: 0.9067 - loss: 0.0490 - learning_rate: 1.2500e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9759 - jaccard_coefficient: 0.9056 - loss: 0.0496\n",
      "Epoch 98: loss improved from 0.05256 to 0.05170, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9758 - jaccard_coefficient: 0.9054 - loss: 0.0497 - learning_rate: 1.2500e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9769 - jaccard_coefficient: 0.9024 - loss: 0.0513\n",
      "Epoch 99: loss improved from 0.05170 to 0.04950, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9769 - jaccard_coefficient: 0.9026 - loss: 0.0513 - learning_rate: 1.2500e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9756 - jaccard_coefficient: 0.9049 - loss: 0.0500\n",
      "Epoch 100: loss improved from 0.04950 to 0.04759, saving model to model/gray2750.weights.h5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9757 - jaccard_coefficient: 0.9051 - loss: 0.0499 - learning_rate: 1.2500e-04\n",
      "attunet output shape: (None, 256, 256, 1)\n",
      "⏱️ Thời gian huấn luyện: 3363.16 giây\n",
      "✅ Accuracy trung bình: 92.50%\n",
      "🔗 Jaccard trung bình: 73.58%\n"
     ]
    }
   ],
   "source": [
    "initial_lr = 0.001\n",
    "optimizer = Adam(learning_rate=initial_lr)\n",
    "input_shape = (256, 256, 1)\n",
    "\n",
    "attunet = attention_unet(input_shape)\n",
    "attunet.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=dice_loss,\n",
    "    metrics=['accuracy', jaccard_coefficient]\n",
    ")\n",
    "\n",
    "model_checkpoint_dir = 'model'\n",
    "\n",
    "checkpoint_path = os.path.join(model_checkpoint_dir, 'cp.ckpt')\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=os.path.join(model_checkpoint_dir, 'gray2750.weights.h5'),\n",
    "    save_weights_only=True,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "early_stopping = EarlyStoppingByAccuracyChange(\n",
    "    monitor='accuracy',\n",
    "    threshold=0.00001,\n",
    "    patience=10,\n",
    "    verbose=1\n",
    ")\n",
    "lr_reduction = ReduceLROnPlateau(monitor='loss',\n",
    "                                  patience=5,\n",
    "                                  verbose=1,\n",
    "                                  factor=0.5,\n",
    "                                  min_lr=0.00001)\n",
    "start_time = time.time()\n",
    "\n",
    "history = attunet.fit(\n",
    "    train_images_gray_clahe, train_masks,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    callbacks=[early_stopping, lr_reduction, checkpoint_callback]\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "avg_accuracy = np.mean(history.history['accuracy'])\n",
    "avg_jaccard = np.mean(history.history['jaccard_coefficient'])\n",
    "\n",
    "print(\"attunet output shape:\", attunet.output_shape)\n",
    "print(f\"⏱️ Thời gian huấn luyện: {training_time:.2f} giây\")\n",
    "print(f\"✅ Accuracy trung bình: {avg_accuracy*100:.2f}%\")\n",
    "print(f\"🔗 Jaccard trung bình: {avg_jaccard*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T13:17:53.354962Z",
     "iopub.status.busy": "2025-10-26T13:17:53.354391Z",
     "iopub.status.idle": "2025-10-26T13:17:54.247872Z",
     "shell.execute_reply": "2025-10-26T13:17:54.247050Z",
     "shell.execute_reply.started": "2025-10-26T13:17:53.354937Z"
    },
    "id": "NnZTSqEcxV0h",
    "outputId": "372a3cad-6c8b-48ba-bd3d-997460bd878f",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "epochs_range = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Accuracy', color='green')\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Loss', color='red')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('Gray_2750_acc_loss.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T13:17:54.248956Z",
     "iopub.status.busy": "2025-10-26T13:17:54.248692Z",
     "iopub.status.idle": "2025-10-26T13:18:22.827554Z",
     "shell.execute_reply": "2025-10-26T13:18:22.826814Z",
     "shell.execute_reply.started": "2025-10-26T13:17:54.248940Z"
    },
    "id": "cKPd6bmWxV0i",
    "outputId": "b94632e6-949e-443c-c8f7-75c93e418936",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Đánh giá không hậu xử lý...\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.9070 - jaccard_coefficient: 0.6586 - loss: 0.2108 \n",
      "Không hậu xử lý - Dice Loss: 0.2444, Accuracy: 90.17%, Jaccard: 61.67%\n",
      "\n",
      "🔧 Đánh giá sau Morphology...\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 633ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 272/272 [00:00<00:00, 1385.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sau Morphology - Dice Loss: 0.2199, Accuracy: 90.27%, Jaccard: 63.94%\n"
     ]
    }
   ],
   "source": [
    "def apply_morphology(mask, kernel_size=3, iterations=1):\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
    "    mask = (mask > 0.5).astype(np.uint8) \n",
    "\n",
    "    closed = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=iterations)\n",
    "\n",
    "    opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel, iterations=iterations)\n",
    "\n",
    "    return opened.astype(np.float32)  \n",
    "\n",
    "print(\"🔍 Đánh giá không hậu xử lý...\")\n",
    "results = attunet.evaluate(test_images_gray_clahe, test_masks, verbose=1)\n",
    "loss, accuracy, jaccard = results\n",
    "print(f\"Không hậu xử lý - Dice Loss: {loss:.4f}, Accuracy: {accuracy*100:.2f}%, Jaccard: {jaccard*100:.2f}%\")\n",
    "\n",
    "print(\"\\n🔧 Đánh giá sau Morphology...\")\n",
    "predictions1 = attunet.predict(test_images_gray_clahe)\n",
    "refined_predictions1 = []\n",
    "\n",
    "for i in tqdm(range(len(test_images_gray_clahe))):\n",
    "    pred = predictions1[i].squeeze()\n",
    "\n",
    "    morph_pred = apply_morphology(pred, kernel_size=7, iterations=2)\n",
    "\n",
    "    refined_predictions1.append(morph_pred)\n",
    "\n",
    "refined_predictions1 = np.expand_dims(np.array(refined_predictions1), axis=-1)\n",
    "accuracy_after = np_accuracy(test_masks, refined_predictions1)\n",
    "jaccard_after = np_jaccard_coefficient(test_masks, refined_predictions1)\n",
    "loss_after = np_dice_loss(test_masks, refined_predictions1)\n",
    "\n",
    "print(f\"Sau Morphology - Dice Loss: {loss_after:.4f}, Accuracy: {accuracy_after*100:.2f}%, Jaccard: {jaccard_after*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-26T13:18:40.443782Z",
     "iopub.status.idle": "2025-10-26T13:18:40.444119Z",
     "shell.execute_reply": "2025-10-26T13:18:40.443971Z",
     "shell.execute_reply.started": "2025-10-26T13:18:40.443955Z"
    },
    "id": "HzByRTFHxV0m",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "attunet.save('/kaggle/working/model/2.0-gray_2750_model.h5')\n",
    "attunet.save('/kaggle/working/model/2.0-gray_2750_model.keras')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7462356,
     "sourceId": 11874149,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7755866,
     "sourceId": 12304679,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7240504,
     "sourceId": 11545735,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
